{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "# cell 1\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel, RBF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pyproj\n",
    "\n",
    "# For interactive display (works in Jupyter)\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "# ── GPU imports ─────────────────────────────────────────────────────────\n",
    "import torch, gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", device)\n",
    "\n",
    "\n",
    "import os, re, pathlib\n",
    "# master image directory – change once here if you move things\n",
    "IMAGES_ROOT = r\"C:\\ASU\\Semester 2\\space robotics and ai\\codeyy\\GP\\images\"\n",
    "\n",
    "def sanitize(txt: str) -> str:\n",
    "    \"\"\"safe folder/file names (letters, digits, underscore)\"\"\"\n",
    "    return re.sub(r'[^0-9A-Za-z_]+', '_', str(txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2\n",
    "def load_data(filename, sep=','):\n",
    "    \"\"\"\n",
    "    Load CSV data with the specified delimiter.\n",
    "    Prints detected columns for verification.\n",
    "    Returns the DataFrame or None on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(filename, sep=sep)\n",
    "        print(f\"{filename} - Detected columns:\", data.columns.tolist())\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3\n",
    "def preprocess_data(data, variable_name):\n",
    "    \"\"\"\n",
    "    Preprocess the data for GP regression:\n",
    "      - Check that required columns ['Latitude', 'Longitude', variable_name] exist.\n",
    "      - Convert them to numeric.\n",
    "      - Remove rows with NaN values.\n",
    "      - Convert WGS84 coordinates to UTM.\n",
    "      - Scale the spatial features using StandardScaler.\n",
    "    Returns (X_scaled, y, scaler).\n",
    "    \"\"\"\n",
    "    required_columns = ['Latitude', 'Longitude', variable_name]\n",
    "    for col in required_columns:\n",
    "        if col not in data.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    data['Latitude'] = pd.to_numeric(data['Latitude'], errors='coerce')\n",
    "    data['Longitude'] = pd.to_numeric(data['Longitude'], errors='coerce')\n",
    "    data[variable_name] = pd.to_numeric(data[variable_name], errors='coerce')\n",
    "\n",
    "    valid_data = data.dropna(subset=['Latitude', 'Longitude', variable_name])\n",
    "    if len(valid_data) == 0:\n",
    "        return np.empty((0, 2)), np.array([]), None\n",
    "\n",
    "    # Convert WGS84 to UTM (Zone 12N)\n",
    "    utm_crs = pyproj.CRS(\"EPSG:32612\")\n",
    "    wgs84_crs = pyproj.CRS(\"EPSG:4326\")\n",
    "    transformer = pyproj.Transformer.from_crs(wgs84_crs, utm_crs, always_xy=True)\n",
    "    valid_data[\"X_coord\"], valid_data[\"Y_coord\"] = transformer.transform(\n",
    "        valid_data[\"Longitude\"].values,\n",
    "        valid_data[\"Latitude\"].values\n",
    "    )\n",
    "\n",
    "    X = valid_data[['Y_coord', 'X_coord']].values\n",
    "    y = valid_data[variable_name].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(f\"Processing {variable_name} - Valid Data Points: {len(X_scaled)}\")\n",
    "    return X_scaled, y, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4\n",
    "def create_grid(X_scaled, scaler, grid_size=150, padding=0.01):\n",
    "    \"\"\"\n",
    "    Create a prediction grid over the scaled spatial extent of X_scaled.\n",
    "    Returns (lat_mesh, lon_mesh, grid_points_scaled).\n",
    "    \"\"\"\n",
    "    if len(X_scaled) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    lat_min, lat_max = X_scaled[:, 0].min(), X_scaled[:, 0].max()\n",
    "    lon_min, lon_max = X_scaled[:, 1].min(), X_scaled[:, 1].max()\n",
    "\n",
    "    lat_range = lat_max - lat_min\n",
    "    lon_range = lon_max - lon_min\n",
    "\n",
    "    lat_min -= padding * lat_range\n",
    "    lat_max += padding * lat_range\n",
    "    lon_min -= padding * lon_range\n",
    "    lon_max += padding * lon_range\n",
    "\n",
    "    lat_grid = np.linspace(lat_min, lat_max, grid_size)\n",
    "    lon_grid = np.linspace(lon_min, lon_max, grid_size)\n",
    "\n",
    "    lon_mesh, lat_mesh = np.meshgrid(lon_grid, lat_grid)\n",
    "    grid_points = np.vstack([lat_mesh.ravel(), lon_mesh.ravel()]).T\n",
    "    grid_points_scaled = grid_points\n",
    "\n",
    "    return lat_mesh, lon_mesh, grid_points_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5*\n",
    "# ── GPyTorch helpers for GPU‐accelerated GP fitting & prediction ──────────\n",
    "\n",
    "class GPModel(ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module  = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = ScaleKernel(kernel).to(device)\n",
    "    def forward(self, x):\n",
    "        return gpytorch.distributions.MultivariateNormal(\n",
    "            self.mean_module(x), self.covar_module(x)\n",
    "        )\n",
    "\n",
    "def train_gp_torch(kernel, X, y, iters=80, lr=0.1):\n",
    "    X_t = torch.as_tensor(X, dtype=torch.float32, device=device)\n",
    "    y_t = torch.as_tensor(y, dtype=torch.float32, device=device)\n",
    "    lik = GaussianLikelihood().to(device)\n",
    "    model = GPModel(X_t, y_t, lik, kernel).to(device)\n",
    "    model.train(); lik.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    mll = ExactMarginalLogLikelihood(lik, model)\n",
    "    for i in range(iters):\n",
    "        optimizer.zero_grad()\n",
    "        loss = -mll(model(X_t), y_t)\n",
    "        loss.backward(); optimizer.step()\n",
    "    return model, lik\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_gp_torch(model, lik, pts, y_mean=0.0):\n",
    "    model.eval(); lik.eval()\n",
    "    P = torch.as_tensor(pts, dtype=torch.float32, device=device)\n",
    "    with gpytorch.settings.fast_pred_var():\n",
    "        pred = lik(model(P))\n",
    "    mu  = pred.mean.cpu().numpy() + y_mean\n",
    "    std = pred.stddev.cpu().numpy()\n",
    "    return mu, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "def plot_mean_prediction(lat_mesh, lon_mesh, y_pred, variable_name, save_path=None):\n",
    "    if lat_mesh is None or lon_mesh is None or y_pred is None:\n",
    "        print(\"No valid grid for plotting.\"); return\n",
    "    plt.figure(figsize=(12,10))\n",
    "    heatmap = plt.contourf(lon_mesh, lat_mesh, y_pred, levels=100, cmap='coolwarm')\n",
    "    plt.xlabel('Longitude', fontsize=16); plt.ylabel('Latitude', fontsize=16)\n",
    "    plt.title(f'Hotspot Map ({variable_name})', fontsize=20)\n",
    "    cbar = plt.colorbar(heatmap); cbar.ax.tick_params(labelsize=14)\n",
    "    cbar.set_label(variable_name, fontsize=16)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=600); print(f\"Saved mean prediction image: {save_path}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 7\n",
    "def plot_uncertainty(lat_mesh, lon_mesh, y_std, variable_name, save_path=None):\n",
    "    if lat_mesh is None or lon_mesh is None or y_std is None:\n",
    "        print(\"No valid grid for plotting.\"); return\n",
    "    plt.figure(figsize=(12,10))\n",
    "    std_map = plt.contourf(lon_mesh, lat_mesh, y_std, levels=100, cmap='viridis')\n",
    "    plt.xlabel('Longitude', fontsize=16); plt.ylabel('Latitude', fontsize=16)\n",
    "    plt.title(f'Uncertainty Map ({variable_name})', fontsize=20)\n",
    "    cbar = plt.colorbar(std_map); cbar.ax.tick_params(labelsize=14)\n",
    "    cbar.set_label('Standard Deviation', fontsize=16)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=600); print(f\"Saved uncertainty image: {save_path}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8\n",
    "def plot_covariance_matrix(cov_matrix, title=\"Covariance Matrix\"):\n",
    "    if cov_matrix is None:\n",
    "        print(\"No covariance matrix to plot.\"); return\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(cov_matrix, interpolation='none', cmap='viridis')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Data Point Index', fontsize=14); plt.ylabel('Data Point Index', fontsize=14)\n",
    "    plt.colorbar(label='Covariance Value')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 9\n",
    "constant_value = 1.0\n",
    "constant_bounds = (1e-3, 1e4)\n",
    "length_scale = 1.0\n",
    "length_scale_bounds = (1e-7, 1e5)\n",
    "nu = 1.5\n",
    "n_restarts_optimizer = 10\n",
    "alpha = 1e-2\n",
    "normalize_y = True\n",
    "grid_size = 200\n",
    "padding = 0.08\n",
    "print(\"Hyperparameter configuration loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 10\n",
    "from gpytorch.kernels import RBFKernel, MaternKernel\n",
    "\n",
    "kernel_dict = {\n",
    "    \"RBF\":            RBFKernel(),\n",
    "    \"Exponential\":    MaternKernel(nu=0.5),\n",
    "    \"Matern_3/2\":     MaternKernel(nu=1.5),\n",
    "    \"Matern_5/2\":     MaternKernel(nu=2.5),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "files = [\n",
    "    r'C:\\ASU\\Semester 2\\space robotics and ai\\codeyy\\GP\\data\\dec6.csv',\n",
    "    r'C:\\ASU\\Semester 2\\space robotics and ai\\codeyy\\GP\\data\\dec17.csv',\n",
    "    r'C:\\ASU\\Semester 2\\space robotics and ai\\codeyy\\GP\\data\\jan31.csv',\n",
    "    r'C:\\ASU\\Semester 2\\space robotics and ai\\codeyy\\GP\\data\\feb15.csv',\n",
    "    r'C:\\ASU\\Semester 2\\space robotics and ai\\codeyy\\GP\\data\\sep19.csv',\n",
    "    r'C:\\ASU\\Semester 2\\space robotics and ai\\codeyy\\GP\\data\\oct3.csv'\n",
    "]\n",
    "results_folder = IMAGES_ROOT            # ← defined up‑top with sanitize()\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "non_sensor_cols = [\n",
    "    'Latitude','Longitude','Time (UTC)',\n",
    "    'Depth (m)','CDOM (ppb)','Turbidity (NTU)'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "import re\n",
    "\n",
    "for file in files:\n",
    "    df = load_data(file)\n",
    "    if df is None: continue\n",
    "    tag = os.path.splitext(os.path.basename(file))[0]\n",
    "    out_root = os.path.join(results_folder, tag)\n",
    "\n",
    "    sensor_vars = [c for c in df.columns if c not in non_sensor_cols]\n",
    "    for var in sensor_vars:\n",
    "        Xs, y, scaler = preprocess_data(df, var)\n",
    "        if y.size == 0: continue\n",
    "        y_mean = y.mean(); y_cent = y - y_mean\n",
    "        lat_mesh, lon_mesh, grid = create_grid(Xs, scaler, grid_size, padding)\n",
    "        if grid is None: continue\n",
    "\n",
    "        for name, kern in kernel_dict.items():\n",
    "            print(f\"▶ Processing {tag} / {var} / {name}\")\n",
    "            model, lik = train_gp_torch(kern.to(device), Xs, y_cent)\n",
    "            mu, std = predict_gp_torch(model, lik, grid, y_mean)\n",
    "            mu  = mu.reshape(lat_mesh.shape)\n",
    "            std = std.reshape(lat_mesh.shape)\n",
    "\n",
    "            date_safe = tag                   # dec6, feb15, …\n",
    "            var_safe  = sanitize(var)         # Temperature (°C) → Temperature_C_\n",
    "            kern_safe = sanitize(name)        # Matern_3/2      → Matern_3_2\n",
    "\n",
    "            folder = os.path.join(results_folder, date_safe, var_safe, kern_safe)\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "            plot_mean_prediction(lat_mesh, lon_mesh, mu,\n",
    "                     f\"{var}–{name}\",\n",
    "                     os.path.join(folder, \"mean.png\"))\n",
    "\n",
    "            plot_uncertainty(lat_mesh, lon_mesh, std,\n",
    "                 f\"{var}–{name}\",\n",
    "                 os.path.join(folder, \"uncert.png\"))   # ← renamed!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13\n",
    "# ── Artificial‐Field Demo on GPU with Boustrophedon (Lawnmower) Sampling ──\n",
    "\n",
    "# 1) Define the true field\n",
    "def true_field(x, y):\n",
    "    return (\n",
    "        np.sin(0.1 * x) * np.cos(0.1 * y) +\n",
    "        0.05 * x + 0.05 * y +\n",
    "        10 * np.exp(-((x - 50)**2 + (y - 50)**2) / (2 * 200))\n",
    "    )\n",
    "\n",
    "# 2) Build the high-res grid\n",
    "x_range = np.linspace(0, 100, 200)\n",
    "y_range = np.linspace(0, 100, 200)\n",
    "lon_mesh_art, lat_mesh_art = np.meshgrid(x_range, y_range)\n",
    "coords_art = np.vstack([lat_mesh_art.ravel(), lon_mesh_art.ravel()]).T\n",
    "Z_true = true_field(coords_art[:, 1], coords_art[:, 0]).reshape(lat_mesh_art.shape)\n",
    "\n",
    "# 3) Generate boustrophedon (lawnmower) samples\n",
    "def generate_lawnmower_samples(x_min, x_max, y_min, y_max, dx, dy):\n",
    "    \"\"\"\n",
    "    Return two arrays (sample_x, sample_y) tracing a boustrophedon pattern:\n",
    "      - rows Δy apart from y_max down to y_min\n",
    "      - points Δx apart along each row\n",
    "      - even rows left→right, odd rows right→left\n",
    "    \"\"\"\n",
    "    xs = np.arange(x_min, x_max + 1e-6, dx)\n",
    "    ys = np.arange(y_max, y_min - 1e-6, -dy)\n",
    "    pts = []\n",
    "    for i, y in enumerate(ys):\n",
    "        row_xs = xs if (i % 2 == 0) else xs[::-1]\n",
    "        for x in row_xs:\n",
    "            pts.append((x, y))\n",
    "    sx, sy = zip(*pts)\n",
    "    return np.array(sx), np.array(sy)\n",
    "\n",
    "# pick your spacings\n",
    "dx, dy = 5.0, 10.0\n",
    "sample_x, sample_y = generate_lawnmower_samples(\n",
    "    x_min=0, x_max=100, y_min=0, y_max=100, dx=dx, dy=dy\n",
    ")\n",
    "z_samples = true_field(sample_x, sample_y)  # ground truth at sample points\n",
    "\n",
    "# 4) Scale sample coordinates\n",
    "train_coords = np.vstack([sample_y, sample_x]).T  # [lat, lon]\n",
    "scaler_art = StandardScaler().fit(train_coords)\n",
    "train_coords_scaled = scaler_art.transform(train_coords)\n",
    "\n",
    "# 5) Scale full grid coordinates\n",
    "grid_coords_art_scaled = scaler_art.transform(coords_art)\n",
    "\n",
    "# 6) GPU train & predict with each kernel\n",
    "for name, kern in kernel_dict.items():\n",
    "    print(f\"▶ Artificial / {name}\")\n",
    "    model, lik = train_gp_torch(kern.to(device),\n",
    "                                train_coords_scaled, z_samples)\n",
    "    mu, std = predict_gp_torch(model, lik, grid_coords_art_scaled)\n",
    "    mu  = mu.reshape(lat_mesh_art.shape)\n",
    "    std = std.reshape(lat_mesh_art.shape)\n",
    "\n",
    "    # 7) Plot true field, prediction, and error\n",
    "    plt.figure(figsize=(18,5))\n",
    "\n",
    "    # True Field\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.contourf(lon_mesh_art, lat_mesh_art, Z_true,\n",
    "                 levels=100, cmap='coolwarm')\n",
    "    plt.title(\"True Field\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # GP Prediction (mean)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.contourf(lon_mesh_art, lat_mesh_art, mu,\n",
    "                 levels=100, cmap='coolwarm')\n",
    "    plt.scatter(sample_x, sample_y, c='k', s=20)\n",
    "    plt.title(f\"GP Prediction ({name})\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Absolute Error\n",
    "    plt.subplot(1,3,3)\n",
    "    err = np.abs(Z_true - mu)\n",
    "    plt.contourf(lon_mesh_art, lat_mesh_art, err,\n",
    "                 levels=100, cmap='viridis')\n",
    "    plt.title(f\"Absolute Error ({name})\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.suptitle(f\"Artificial Field GP Regression with {name}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
