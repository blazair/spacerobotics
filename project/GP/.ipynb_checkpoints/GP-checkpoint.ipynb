{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'encodings'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.linalg import cholesky, solve_triangular\n",
    "from scipy.special import kv, gamma\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Read a Single CSV File\n",
    "csv_file = \"/home/blazar/Codes/GP/Data/feb15.csv\"\n",
    "\n",
    "# Read file into a DataFrame\n",
    "data = pd.read_csv(csv_file)\n",
    "print(f\"Loaded {len(data)} data points from: {csv_file}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First few rows of raw data:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Preprocess Data: Convert Time, Latitude/Longitude, and Depth\n",
    "\n",
    "# --- LATITUDE & LONGITUDE ---\n",
    "# Here we keep lat/lon as-is (we store Latitude in Y_coord and Longitude in X_coord)\n",
    "data[\"Y_coord\"] = data[\"Latitude\"]\n",
    "data[\"X_coord\"] = data[\"Longitude\"]\n",
    "\n",
    "# --- DEPTH ---\n",
    "data[\"Depth_m\"] = data[\"Depth (Sonar)\"]\n",
    "\n",
    "# Show a sample of the processed data\n",
    "print(\"Sample processed data:\")\n",
    "print(data[[\"Latitude\", \"Longitude\", \"X_coord\", \"Y_coord\", \"Depth_m\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Subsample Data and Define Feature/Target Arrays\n",
    "\n",
    "max_points_per_file = 20000\n",
    "n = len(data)\n",
    "sampled_indices = data.sample(min(n, max_points_per_file), random_state=42).index\n",
    "sampled_indices = sorted(sampled_indices)\n",
    "\n",
    "# Define target variable (Temperature)\n",
    "target_var = \"Temperature (°C)\"\n",
    "y = data[target_var].values\n",
    "\n",
    "# Define the 3D feature matrix for GP: [X_coord, Y_coord, Depth_m]\n",
    "X_features = data[[\"X_coord\", \"Y_coord\", \"Depth_m\"]].values\n",
    "\n",
    "# Create training set (for GP)\n",
    "X_train = X_features[sampled_indices]\n",
    "y_train = y[sampled_indices]\n",
    "\n",
    "print(f\"Total data points: {len(data)}, Training subset size: {X_train.shape[0]}\")\n",
    "print(\"Example training point (3D):\", X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Hyperparameters and Nonstationary Matérn Kernel\n",
    "\n",
    "nu = 1.5                    # Matérn smoothness\n",
    "sigma_f = np.std(y_train)   # Signal scale\n",
    "sigma_n = 0.1               # Noise std\n",
    "base_lengthscale_space = 0.0001  # Base spatial length-scale (in degrees, if lat/lon remain in degrees)\n",
    "lengthscale_depth = 2       # Depth length-scale (m)\n",
    "\n",
    "print(\"\\nHyperparameters:\")\n",
    "print(f\"nu = {nu}, sigma_f = {sigma_f:.2f}, sigma_n = {sigma_n}\")\n",
    "print(f\"base_lengthscale_space = {base_lengthscale_space}, lengthscale_depth = {lengthscale_depth}\")\n",
    "\n",
    "def Sigma_matrix(x, rho_xy=0.2, rho_xz=0.1, rho_yz=0.15):\n",
    "    \"\"\"\n",
    "    Computes the full covariance matrix Σ(x) with off-diagonal correlations.\n",
    "    \"\"\"\n",
    "    sigma_x = base_lengthscale_space * np.exp(-0.1 * x[2])\n",
    "    sigma_y = sigma_x  # assume same spatial scale for simplicity\n",
    "    sigma_z = lengthscale_depth\n",
    "    Sigma = np.array([\n",
    "        [sigma_x**2, rho_xy * sigma_x * sigma_y, rho_xz * sigma_x * sigma_z],\n",
    "        [rho_xy * sigma_x * sigma_y, sigma_y**2, rho_yz * sigma_y * sigma_z],\n",
    "        [rho_xz * sigma_x * sigma_z, rho_yz * sigma_y * sigma_z, sigma_z**2]\n",
    "    ])\n",
    "    return Sigma\n",
    "\n",
    "# Example usage:\n",
    "sample_x = [0, 0, 5]  # for a point at depth 5\n",
    "Sigma_ex = Sigma_matrix(sample_x)\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(Sigma_ex)\n",
    "print(\"Full Covariance Matrix Σ(x):\\n\", Sigma_ex)\n",
    "print(\"Eigenvalues:\\n\", eigenvalues)\n",
    "print(\"Eigenvectors:\\n\", eigenvectors)\n",
    "\n",
    "\n",
    "def matern_covariance(x, x_prime, nu=nu, sigma_f=sigma_f):\n",
    "    \"\"\"\n",
    "    Computes the Nonstationary Matérn covariance between x and x_prime.\n",
    "    Adjusted for a 3D input vector (X_coord, Y_coord, Depth_m).\n",
    "    \"\"\"\n",
    "    Σ_i = Sigma_matrix(x)  # 3x3 matrix\n",
    "    Σ_j = Sigma_matrix(x_prime)  # 3x3 matrix\n",
    "    det_Si = np.linalg.det(Σ_i)\n",
    "    det_Sj = np.linalg.det(Σ_j)\n",
    "    det_half = np.linalg.det((Σ_i + Σ_j) / 2.0)\n",
    "    diff = np.array(x) - np.array(x_prime)  # 3D difference vector\n",
    "    M = (Σ_i + Σ_j) / 2.0  # 3x3 matrix\n",
    "\n",
    "    # Mahalanobis-like distance Q_ij\n",
    "    try:\n",
    "        v = np.linalg.solve(M, diff)\n",
    "        Q_ij = float(diff.dot(v))\n",
    "    except np.linalg.LinAlgError:\n",
    "        v = np.linalg.pinv(M).dot(diff)\n",
    "        Q_ij = float(diff.dot(v))\n",
    "\n",
    "    if Q_ij < 1e-12:\n",
    "        return sigma_f**2\n",
    "\n",
    "    prefactor = (det_Si**0.25) * (det_Sj**0.25) / (det_half**0.5)\n",
    "    arg = np.sqrt(2 * nu * Q_ij)\n",
    "    matern_part = (arg**nu) * kv(nu, arg)\n",
    "    norm_const = 1.0 / (gamma(nu) * 2**(nu - 1))\n",
    "    \n",
    "    return sigma_f**2 * prefactor * norm_const * matern_part\n",
    "\n",
    "print(\"\\nNonstationary Matérn kernel defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Compute Kernel Matrix and Cholesky Decomposition\n",
    "\n",
    "N = X_train.shape[0]\n",
    "print(f\"\\nComputing kernel matrix for {N} training points...\")\n",
    "K = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    for j in range(i, N):\n",
    "        cov_ij = matern_covariance(X_train[i], X_train[j])\n",
    "        K[i, j] = cov_ij\n",
    "        K[j, i] = cov_ij\n",
    "    if i % 50 == 0:\n",
    "        print(f\"Processed {i}/{N} rows\")\n",
    "\n",
    "print(\"Kernel matrix computed. Shape:\", K.shape)\n",
    "\n",
    "K += (sigma_n**2) * np.eye(N)\n",
    "print(\"Noise variance added to the diagonal of K.\")\n",
    "\n",
    "print(\"Performing Cholesky decomposition...\")\n",
    "L = cholesky(K, lower=True)\n",
    "print(\"Cholesky decomposition complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Compute GP Weights and Predictions\n",
    "\n",
    "print(\"Solving for GP weights (α)...\")\n",
    "alpha = solve_triangular(L.T, solve_triangular(L, y_train, lower=True), lower=False)\n",
    "print(\"GP weights computed.\")\n",
    "\n",
    "# Generate test grid for spatial domain using X_coord and Y_coord\n",
    "test_depth = 1.0  # Fixed depth for test predictions\n",
    "grid_x = np.linspace(data[\"X_coord\"].min(), data[\"X_coord\"].max(), 50)\n",
    "grid_y = np.linspace(data[\"Y_coord\"].min(), data[\"Y_coord\"].max(), 50)\n",
    "\n",
    "# Build X_test: each point is [X_coord, Y_coord, Depth_m]\n",
    "X_test = np.array([[xx, yy, test_depth] for xx in grid_x for yy in grid_y])\n",
    "print(f\"Generated {X_test.shape[0]} test points for prediction.\")\n",
    "\n",
    "print(\"Computing cross-covariance K_star...\")\n",
    "K_star = np.array([[matern_covariance(x, xi) for xi in X_train] for x in X_test])\n",
    "print(\"Cross-covariance computed.\")\n",
    "\n",
    "mu_pred = K_star @ alpha\n",
    "print(\"Mean predictions computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Visualization - GP Mean Prediction and Uncertainty\n",
    "\n",
    "# Reshape predictions to grid for contour plotting\n",
    "Mu_grid = mu_pred.reshape(len(grid_x), len(grid_y)).T\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cs = plt.contourf(grid_x, grid_y, Mu_grid, cmap=\"viridis\", levels=15)\n",
    "plt.colorbar(cs, label=\"Predicted Temperature (°C)\")\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c='white', s=5, edgecolors='k', label=\"Training points\")\n",
    "plt.title(\"GP Mean Prediction (Temperature)\")\n",
    "plt.xlabel(\"X_coord (Longitude)\")\n",
    "plt.ylabel(\"Y_coord (Latitude)\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"GP Mean Prediction plot displayed.\")\n",
    "\n",
    "# Compute predictive variance\n",
    "print(\"Computing predictive variance...\")\n",
    "v = solve_triangular(L, K_star.T, lower=True)\n",
    "K_ss_diag = np.array([matern_covariance(x, x) for x in X_test])\n",
    "var_pred = K_ss_diag - np.sum(v**2, axis=0)\n",
    "var_pred = np.maximum(var_pred, 1e-10)\n",
    "std_pred = np.sqrt(var_pred)\n",
    "\n",
    "Std_grid = std_pred.reshape(len(grid_x), len(grid_y)).T\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cs2 = plt.contourf(grid_x, grid_y, Std_grid, cmap=\"plasma\", levels=15)\n",
    "plt.colorbar(cs2, label=\"Predictive Standard Deviation (°C)\")\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c='white', s=5, edgecolors='k')\n",
    "plt.title(\"GP Uncertainty (Standard Deviation) - Temperature\")\n",
    "plt.xlabel(\"X_coord (Longitude)\")\n",
    "plt.ylabel(\"Y_coord (Latitude)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"GP Uncertainty plot displayed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Additional Analysis\n",
    "\n",
    "# Plot correlation matrix (using all available columns)\n",
    "corr_vars = [\"Latitude\", \"Longitude\", \"Depth_m\"]\n",
    "corr_matrix = data[corr_vars].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix: Time, Latitude, Longitude, Depth\")\n",
    "plt.show()\n",
    "print(\"Correlation heatmap displayed.\")\n",
    "\n",
    "print(\"Latitude range:\", data[\"Latitude\"].min(), data[\"Latitude\"].max())\n",
    "print(\"Longitude range:\", data[\"Longitude\"].min(), data[\"Longitude\"].max())\n",
    "print(\"Depth range:\", data[\"Depth (Sonar)\"].min(), data[\"Depth (Sonar)\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1D grid over which to define our \"eigenvalue process\"\n",
    "X = np.linspace(0, 10, 100)[:, None]\n",
    "\n",
    "# Define a Matérn kernel (you might fix nu=2.5 for smoothness, as in the paper they use a very smooth GP for eigenprocesses)\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=1.0, nu=2.5)\n",
    "\n",
    "# Compute the covariance matrix for our grid\n",
    "K = kernel(X)\n",
    "\n",
    "# Draw samples from the GP prior (mean is zero here)\n",
    "n_samples = 3\n",
    "samples = np.random.multivariate_normal(np.zeros(X.shape[0]), K, n_samples)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_samples):\n",
    "    plt.plot(X, samples[i], label=f'Sample {i+1}')\n",
    "plt.title('Samples from a GP Prior for an Eigenvalue Process')\n",
    "plt.xlabel('Input (e.g., spatial location)')\n",
    "plt.ylabel('Log Eigenvalue')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
